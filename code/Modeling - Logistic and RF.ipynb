{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to run Logistic Regression on a few different feature selections.\n",
    "\n",
    "Just as a reminder, here is the key for my dataframes:\n",
    "\n",
    " - df_games_X_1 = All (dummy drop 1, on_pace instead of current_by_remaining_rate to avoid non-linear model) Logistic\n",
    " - df_games_X_2 = All (one hot no drop, current_by_remaining_rate, to use in RF) RF\n",
    " - df_games_X_3 = Non-text features (dummy drop 1, on_pace instead of current_by_remaining_rate to avoid non-linear model) Logistic\n",
    " - df_games_X_4 = Non-text features (one hot no drop, current_by_remaining_rate, to use in RF) RF\n",
    " - df_games_X_5 = Only text features Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/final/df_games_X_1.pickle', 'rb') as f:\n",
    "    df_games_X_1 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_4/model_data/final/df_games_X_2.pickle', 'rb') as f:\n",
    "    df_games_X_2 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_4/model_data/final/df_games_X_3.pickle', 'rb') as f:\n",
    "    df_games_X_3 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_4/model_data/final/df_games_X_4.pickle', 'rb') as f:\n",
    "    df_games_X_4 = pickle.load(f)\n",
    "    \n",
    "with open('/Users/robertpagano/metis_data/project_4/model_data/final/df_games_X_5.pickle', 'rb') as f:\n",
    "    df_games_X_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Logistic, I am going to use X_1, X_3, and X_5.\n",
    "\n",
    "I don't expect X_5 to be nearly as good, but it could be interesting to see how much the LSA text information is predictive. I can also use this later (or now) to tune how many components by cross validating with different numbers. That should be pretty simple once I have the \"pipeline\"\n",
    "\n",
    "Also, just as a note to myself, my \"y\" values will always be the same, so I should only have one y_test and y_train. Using the same random state in the same function call should do this. I'll write some code just to double check that the values are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df_games_X_1.iloc[:, 1:]\n",
    "y_1 = df_games_X_1.iloc[:, 0]\n",
    "\n",
    "X_2 = df_games_X_2.iloc[:, 1:]\n",
    "y_2 = df_games_X_2.iloc[:, 0]\n",
    "\n",
    "X_3 = df_games_X_3.iloc[:, 1:]\n",
    "y_3 = df_games_X_3.iloc[:, 0]\n",
    "\n",
    "X_4 = df_games_X_4.iloc[:, 1:]\n",
    "y_4 = df_games_X_4.iloc[:, 0]\n",
    "\n",
    "X_5 = df_games_X_5.iloc[:, 1:]\n",
    "y_5 = df_games_X_5.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1, y_1, test_size=0.2, random_state=42)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2, y_2, test_size=0.2, random_state=42)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_3, y_3, test_size=0.2, random_state=42)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X_4, y_4, test_size=0.2, random_state=42)\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X_5, y_5, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Just checking that all of the y splits are the same\n",
    "print(np.all(y1_train == y2_train))\n",
    "print(np.all(y1_test == y2_test))\n",
    "print(np.all(y2_train == y3_train))\n",
    "print(np.all(y2_test == y3_test))\n",
    "print(np.all(y3_train == y4_train))\n",
    "print(np.all(y3_test == y4_test))\n",
    "print(np.all(y4_train == y5_train))\n",
    "print(np.all(y4_test == y5_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success - so now moving on to cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_games_X_1\n",
    "logreg1 = LogisticRegression()\n",
    "\n",
    "# for df_games_X_3\n",
    "logreg3 = LogisticRegression()\n",
    "\n",
    "# for df_games_X_5\n",
    "logreg5 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'warn',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'warn',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "pprint(logreg.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_games_X_1\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "# for df_games_X_3\n",
    "scaler3 = StandardScaler()\n",
    "\n",
    "# for df_games_X_5\n",
    "scaler5 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1.fit(X1_train.values)\n",
    "X1_tr = scaler1.transform(X1_train.values)\n",
    "X1_te = scaler1.transform(X1_test.values)\n",
    "\n",
    "scaler3.fit(X3_train.values)\n",
    "X3_tr = scaler3.transform(X3_train.values)\n",
    "X3_te = scaler3.transform(X3_test.values)\n",
    "\n",
    "scaler5.fit(X5_train.values)\n",
    "X5_tr = scaler5.transform(X5_train.values)\n",
    "X5_te = scaler5.transform(X5_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# pick a solver\n",
    "solver = ['lbfgs', 'liblinear']\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty, solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### # for df_games_X_1\n",
    "# Create grid search using 3-fold cross validation\n",
    "logreg_clf1 = GridSearchCV(logreg, hyperparameters, cv=3, verbose=0)\n",
    "\n",
    "# Fit grid search with scaled x values and y tain\n",
    "best_logreg_model1 = logreg_clf1.fit(X1_tr, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "### # for df_games_X_3\n",
    "# Create grid search using 3-fold cross validation\n",
    "logreg_clf3 = GridSearchCV(logreg, hyperparameters, cv=3, verbose=0)\n",
    "\n",
    "# Fit grid search with scaled x values and y tain\n",
    "best_logreg_model3 = logreg_clf3.fit(X3_tr, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # for df_games_X_5\n",
    "# Create grid search using 3-fold cross validation\n",
    "logreg_clf5 = GridSearchCV(logreg, hyperparameters, cv=3, verbose=0)\n",
    "\n",
    "# Fit grid search with scaled x values and y tain\n",
    "best_logreg_model5 = logreg_clf5.fit(X5_tr, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171785638635882"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg_model1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best C:', best_logreg_model1.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165431052743063"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg_model3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best C:', best_logreg_model3.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6752806608769328"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg_model5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 2.7825594022071245\n"
     ]
    }
   ],
   "source": [
    "print('Best C:', best_logreg_model5.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first results are based on All features - numeric, categorical, and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.9049429657794678\n",
      "Accuracy test score is 0.9153259949195597\n",
      "precision test score is 0.8717948717948718\n",
      "recall test score is 0.9407114624505929\n",
      "AUC test score is 0.9185038793734446\n"
     ]
    }
   ],
   "source": [
    "f1_best_logreg_model1 = f1_score(best_logreg_model1.predict(X1_te), y1_test)\n",
    "accuracy_best_logreg_model1 = accuracy_score(best_logreg_model1.predict(X1_te), y1_test)\n",
    "precision_best_logreg_model1 = precision_score(best_logreg_model1.predict(X1_te), y1_test)\n",
    "recall_best_logreg_model1 = recall_score(best_logreg_model1.predict(X1_te), y1_test)\n",
    "AUC_best_logreg_model1 = roc_auc_score(best_logreg_model1.predict(X1_te), y1_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_logreg_model1}')\n",
    "print(f'Accuracy test score is {accuracy_best_logreg_model1}')\n",
    "print(f'precision test score is {precision_best_logreg_model1}')\n",
    "print(f'recall test score is {recall_best_logreg_model1}')\n",
    "print(f'AUC test score is {AUC_best_logreg_model1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is just on numeric and categorical, slightly better than with text, but not by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.9116809116809116\n",
      "Accuracy test score is 0.9212531752751905\n",
      "precision test score is 0.8791208791208791\n",
      "recall test score is 0.9467455621301775\n",
      "AUC test score is 0.9244113567327445\n"
     ]
    }
   ],
   "source": [
    "f1_best_logreg_model3 = f1_score(best_logreg_model3.predict(X3_te), y1_test)\n",
    "accuracy_best_logreg_model3 = accuracy_score(best_logreg_model3.predict(X3_te), y1_test)\n",
    "precision_best_logreg_model3 = precision_score(best_logreg_model3.predict(X3_te), y1_test)\n",
    "recall_best_logreg_model3 = recall_score(best_logreg_model3.predict(X3_te), y1_test)\n",
    "AUC_best_logreg_model3 = roc_auc_score(best_logreg_model3.predict(X3_te), y1_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_logreg_model3}')\n",
    "print(f'Accuracy test score is {accuracy_best_logreg_model3}')\n",
    "print(f'precision test score is {precision_best_logreg_model3}')\n",
    "print(f'recall test score is {recall_best_logreg_model3}')\n",
    "print(f'AUC test score is {AUC_best_logreg_model3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most surprising, my DF with *only* text features still seems somewhat decent. Predicting correctly 68% of the time!\n",
    "\n",
    "The fact that precision is low makes me think it's favoring predicting in the positive, even though the data is slightly skewed towards negative.\n",
    "\n",
    "This really makes me want to do some k-means clustering - what I should do is go through my rf models, see how those work, and then come back to this. First step - try different numbers of topics (10,20,30,40,50, maybe more, it's cheap to run). When I pick my number of topics, then do kmeans and figure out my clusters.\n",
    "\n",
    "Once I am done with that, really all I need to do is build the recommender and slides, because I think my model is good enough at this point to move on. Just need to make sure I do something with my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.6047471620227038\n",
      "Accuracy test score is 0.6756985605419137\n",
      "precision test score is 0.5366300366300366\n",
      "recall test score is 0.6926713947990544\n",
      "AUC test score is 0.6794491538639071\n"
     ]
    }
   ],
   "source": [
    "f1_best_logreg_model5 = f1_score(best_logreg_model5.predict(X5_te), y1_test)\n",
    "accuracy_best_logreg_model5 = accuracy_score(best_logreg_model5.predict(X5_te), y1_test)\n",
    "precision_best_logreg_model5 = precision_score(best_logreg_model5.predict(X5_te), y1_test)\n",
    "recall_best_logreg_model5 = recall_score(best_logreg_model5.predict(X5_te), y1_test)\n",
    "AUC_best_logreg_model5 = roc_auc_score(best_logreg_model5.predict(X5_te), y1_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_logreg_model5}')\n",
    "print(f'Accuracy test score is {accuracy_best_logreg_model5}')\n",
    "print(f'precision test score is {precision_best_logreg_model5}')\n",
    "print(f'recall test score is {recall_best_logreg_model5}')\n",
    "print(f'AUC test score is {AUC_best_logreg_model5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest setup and modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 'warn',\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.0min\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 25.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random2 = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 70,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.9322191272051995\n",
      "Accuracy test score is 0.9381879762912786\n",
      "precision test score is 0.9194139194139194\n",
      "recall test score is 0.9453860640301318\n",
      "AUC test score is 0.9388468781689121\n"
     ]
    }
   ],
   "source": [
    "f1_best_rf_2 = f1_score(rf_random2.predict(X2_test), y2_test)\n",
    "accuracy_best_rf_2 = accuracy_score(rf_random2.predict(X2_test), y2_test)\n",
    "precision_best_rf_2 = precision_score(rf_random2.predict(X2_test), y2_test)\n",
    "recall_best_rf_2 = recall_score(rf_random2.predict(X2_test), y2_test)\n",
    "AUC_best_rf_2 = roc_auc_score(rf_random2.predict(X2_test), y2_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_rf_2}')\n",
    "print(f'Accuracy test score is {accuracy_best_rf_2}')\n",
    "print(f'precision test score is {precision_best_rf_2}')\n",
    "print(f'recall test score is {recall_best_rf_2}')\n",
    "print(f'AUC test score is {AUC_best_rf_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list2 = list(X_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances2 = list(rf_random2.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_2 = list(zip(feature_list2, importances2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_2_sorted = feature_importances_2.sort(key = lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random4 = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random4.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.9417206290471785\n",
      "Accuracy test score is 0.9466553767993227\n",
      "precision test score is 0.9322344322344323\n",
      "recall test score is 0.9514018691588785\n",
      "AUC test score is 0.9470631636816064\n"
     ]
    }
   ],
   "source": [
    "f1_best_rf_4 = f1_score(rf_random4.predict(X4_test), y4_test)\n",
    "accuracy_best_rf_4 = accuracy_score(rf_random4.predict(X4_test), y4_test)\n",
    "precision_best_rf_4 = precision_score(rf_random4.predict(X4_test), y4_test)\n",
    "recall_best_rf_4 = recall_score(rf_random4.predict(X4_test), y4_test)\n",
    "AUC_best_rf_4 = roc_auc_score(rf_random4.predict(X4_test), y4_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_rf_4}')\n",
    "print(f'Accuracy test score is {accuracy_best_rf_4}')\n",
    "print(f'precision test score is {precision_best_rf_4}')\n",
    "print(f'recall test score is {recall_best_rf_4}')\n",
    "print(f'AUC test score is {AUC_best_rf_4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list4 = list(X_4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances4 = list(rf_random4.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_4 = list(zip(feature_list4, importances4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_4_sorted = feature_importances_4.sort(key = lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('current_by_remaining_rate', 0.41301342500185), ('category_name_x_Tabletop Games', 0.1931369509429096), ('money_needed_by_day', 0.10367270726096926), ('category_name_x_Mobile Games', 0.0408090406353065), ('time_to_launch', 0.029204292540369065), ('category_name_x_Playing Cards', 0.026071441753620042), ('name_char_count', 0.020155167405576956), ('year_launched_str_2016', 0.01750310471372906), ('category_name_x_Video Games', 0.017124925509723075), ('day_limit', 0.016595403454359295), ('year_launched_str_2018', 0.015253028637668009), ('blurb_char_count', 0.015216546905151418), ('category_name_x_Live Games', 0.01139120632447556), ('staff_pick_num', 0.010435587293570664), ('category_name_x_Games', 0.004040709388651512), ('year_launched_str_2017', 0.0035899442053298814), ('day_of_week_launched_Tuesday', 0.003409097246680449), ('category_name_x_Gaming Hardware', 0.003215726945065918), ('month_launched_January', 0.0026500616700895524), ('month_launched_March', 0.002582605460405011), ('country_US', 0.002428447856491272), ('day_of_week_launched_Wednesday', 0.0023386316547062613), ('month_launched_June', 0.0022087609917111665), ('month_launched_October', 0.002182701177828817), ('month_launched_February', 0.0021044726023846734), ('category_name_x_Puzzles', 0.0021005445656446155), ('day_of_week_launched_Monday', 0.002099333726560889), ('day_of_week_launched_Saturday', 0.0019194294330075285), ('month_launched_September', 0.0018866707850379364), ('day_of_week_launched_Friday', 0.0018773641189247174), ('month_launched_July', 0.0018741866965433583), ('day_of_week_launched_Thursday', 0.001809182811745458), ('month_launched_December', 0.0017784535203042603), ('month_launched_August', 0.0017640267870189584), ('month_launched_November', 0.0017541054949625655), ('country_GB', 0.0016960459285089906), ('month_launched_May', 0.001609168410316454), ('country_FR', 0.0016073015699548626), ('country_AU', 0.001535572595347241), ('country_CA', 0.0014766752764639186), ('day_of_week_launched_Sunday', 0.0014631563521831184), ('month_launched_April', 0.0013570951525416564), ('country_IT', 0.0013381728456845947), ('country_DE', 0.0013334430581648908), ('country_ES', 0.0008544975829998396), ('year_launched_str_2019', 0.0007901923873756342), ('country_CH', 0.0006944755170745185), ('country_SE', 0.0006759147362553369), ('country_NL', 0.0006463699622033308), ('country_MX', 0.0005595318697998844), ('country_NO', 0.000529063011188827), ('country_NZ', 0.0005135745556456153), ('country_DK', 0.0004835697602665856), ('year_launched_str_2015', 0.0003893422836366061), ('country_HK', 0.00027082438445277704), ('country_JP', 0.00023598803287698048), ('country_BE', 0.00021205840051155046), ('country_SG', 0.0001881803018301772), ('country_IE', 0.0001782024809066946), ('country_AT', 0.00015872547216739865), ('country_LU', 5.572553269065497e-06)]\n"
     ]
    }
   ],
   "source": [
    "print(list(feature_importances_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.6min\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 30.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random5 = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random5.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 test score is 0.5714285714285714\n",
      "Accuracy test score is 0.6621507197290432\n",
      "precision test score is 0.48717948717948717\n",
      "recall test score is 0.6909090909090909\n",
      "AUC test score is 0.6695751484696209\n"
     ]
    }
   ],
   "source": [
    "f1_best_rf_5 = f1_score(rf_random5.predict(X5_test), y5_test)\n",
    "accuracy_best_rf_5 = accuracy_score(rf_random5.predict(X5_test), y5_test)\n",
    "precision_best_rf_5 = precision_score(rf_random5.predict(X5_test), y5_test)\n",
    "recall_best_rf_5 = recall_score(rf_random5.predict(X5_test), y5_test)\n",
    "AUC_best_rf_5 = roc_auc_score(rf_random5.predict(X5_test), y5_test)\n",
    "\n",
    "print(f'F1 test score is {f1_best_rf_5}')\n",
    "print(f'Accuracy test score is {accuracy_best_rf_5}')\n",
    "print(f'precision test score is {precision_best_rf_5}')\n",
    "print(f'recall test score is {recall_best_rf_5}')\n",
    "print(f'AUC test score is {AUC_best_rf_5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list5 = list(X_5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances5 = list(rf_random5.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_5 = list(zip(feature_list5, importances5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_5_sorted = feature_importances_5.sort(key = lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_model_logreg = best_logreg_model1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_model_rf = rf_random2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_model_logreg = best_logreg_model3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4_model_rf = rf_random4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5_model_logreg = best_logreg_model5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5_model_rf = rf_random5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_1_model_logreg.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_1_model_logreg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_2_model_rf.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_2_model_rf, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_3_model_logreg.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_3_model_logreg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_4_model_rf.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_4_model_rf, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_5_model_logreg.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_5_model_logreg, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/robertpagano/metis_data/project_4/model_data/model_pickles/X_5_model_rf.pickle', 'wb') as to_write:\n",
    "    pickle.dump(X_5_model_rf, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
